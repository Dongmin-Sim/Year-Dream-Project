{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "(Student)4_fancy_rnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0M47aJDTXtbL"
      },
      "source": [
        "##**4. LSTM, GRU**\n",
        "1. 기존 RNN과 다른 부분에 대해서 배웁니다.\n",
        "2. 이전 실습에 이어 다양한 적용법을 배웁니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBoAWPAJSI2D"
      },
      "source": [
        "### **필요 패키지 import**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEnlDHarWusL"
      },
      "source": [
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "import torch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sze4MVwxSYPR"
      },
      "source": [
        "### **데이터 전처리**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugKWDpQrSY3o"
      },
      "source": [
        "아래의 sample data를 확인해봅시다.  \n",
        "이전 실습과 동일합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWjwZOmGYMhw"
      },
      "source": [
        "vocab_size = 100\n",
        "pad_id = 0\n",
        "\n",
        "data = [\n",
        "  [85,14,80,34,99,20,31,65,53,86,3,58,30,4,11,6,50,71,74,13],\n",
        "  [62,76,79,66,32],\n",
        "  [93,77,16,67,46,74,24,70],\n",
        "  [19,83,88,22,57,40,75,82,4,46],\n",
        "  [70,28,30,24,76,84,92,76,77,51,7,20,82,94,57],\n",
        "  [58,13,40,61,88,18,92,89,8,14,61,67,49,59,45,12,47,5],\n",
        "  [22,5,21,84,39,6,9,84,36,59,32,30,69,70,82,56,1],\n",
        "  [94,21,79,24,3,86],\n",
        "  [80,80,33,63,34,63],\n",
        "  [87,32,79,65,2,96,43,80,85,20,41,52,95,50,35,96,24,80]\n",
        "]"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmqlfxW_Tsfm",
        "outputId": "7d4e6e3b-015e-4d25-fb0b-f7d7222086a3"
      },
      "source": [
        "max_len = len(max(data, key=len))\n",
        "print(f\"Maximum sequence length: {max_len}\")\n",
        "\n",
        "valid_lens = []\n",
        "for i, seq in enumerate(tqdm(data)):\n",
        "  valid_lens.append(len(seq))\n",
        "  if len(seq) < max_len:\n",
        "    data[i] = seq + [pad_id] * (max_len - len(seq))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum sequence length: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 58416.49it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znWCR7UbTvVE",
        "outputId": "d1ebec93-66fb-4775-ede6-25ae811b9922"
      },
      "source": [
        "# B: batch size, L: maximum sequence length\n",
        "batch = torch.LongTensor(data)  # (B, L)\n",
        "batch_lens = torch.LongTensor(valid_lens)  # (B)\n",
        "\n",
        "batch_lens, sorted_idx = batch_lens.sort(descending=True)\n",
        "batch = batch[sorted_idx]\n",
        "\n",
        "print(batch)\n",
        "print(batch.shape)\n",
        "print(batch_lens)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[85, 14, 80, 34, 99, 20, 31, 65, 53, 86,  3, 58, 30,  4, 11,  6, 50, 71,\n",
            "         74, 13],\n",
            "        [58, 13, 40, 61, 88, 18, 92, 89,  8, 14, 61, 67, 49, 59, 45, 12, 47,  5,\n",
            "          0,  0],\n",
            "        [87, 32, 79, 65,  2, 96, 43, 80, 85, 20, 41, 52, 95, 50, 35, 96, 24, 80,\n",
            "          0,  0],\n",
            "        [22,  5, 21, 84, 39,  6,  9, 84, 36, 59, 32, 30, 69, 70, 82, 56,  1,  0,\n",
            "          0,  0],\n",
            "        [70, 28, 30, 24, 76, 84, 92, 76, 77, 51,  7, 20, 82, 94, 57,  0,  0,  0,\n",
            "          0,  0],\n",
            "        [19, 83, 88, 22, 57, 40, 75, 82,  4, 46,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0],\n",
            "        [93, 77, 16, 67, 46, 74, 24, 70,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0],\n",
            "        [94, 21, 79, 24,  3, 86,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0],\n",
            "        [80, 80, 33, 63, 34, 63,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0],\n",
            "        [62, 76, 79, 66, 32,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0]])\n",
            "torch.Size([10, 20])\n",
            "tensor([20, 18, 18, 17, 15, 10,  8,  6,  6,  5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPRtdhHoUKhH"
      },
      "source": [
        "### **LSTM 사용**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1FvfENCUqYN"
      },
      "source": [
        "LSTM에선 cell state가 추가됩니다.  \n",
        "Cell state의 shape는 hidden state의 그것과 동일합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q76VGoCCUrcQ"
      },
      "source": [
        "embedding_size = 256\n",
        "hidden_size = 512\n",
        "num_layers = 1\n",
        "num_dirs = 1\n",
        "\n",
        "embedding = nn.Embedding(vocab_size, embedding_size)\n",
        "# ---------------------fill in ------------------------\n",
        "lstm = nn.LSTM(\n",
        "    input_size=embedding_size,\n",
        "    hidden_size=hidden_size,\n",
        "    num_layers=num_layers,\n",
        "    bidirectional= True if num_dirs > 1 else False\n",
        ")\n",
        "\n",
        "h_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))  # (num_layers * num_dirs, B, d_h)\n",
        "c_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))  # (num_layers * num_dirs, B, d_h)\n",
        "# ---------------------fill in ------------------------"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhS7qvIKWYYb",
        "outputId": "70bb87f0-f0d0-4f69-bca0-b09e5eb1144e"
      },
      "source": [
        "# d_w: word embedding size\n",
        "batch_emb = embedding(batch)  # (B, L, d_w)\n",
        "\n",
        "# pack_padded\n",
        "packed_batch = pack_padded_sequence(batch_emb.transpose(0, 1), batch_lens)\n",
        "\n",
        "packed_outputs, (h_n, c_n) = lstm(packed_batch, (h_0, c_0))\n",
        "print(packed_outputs)\n",
        "print(packed_outputs[0].shape)\n",
        "print(h_n.shape)\n",
        "print(c_n.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PackedSequence(data=tensor([[ 0.0745, -0.0430, -0.0226,  ...,  0.0362,  0.0446,  0.0281],\n",
            "        [ 0.0598, -0.1183, -0.0041,  ..., -0.1658, -0.2191, -0.1804],\n",
            "        [ 0.0500, -0.1667,  0.0569,  ...,  0.0324, -0.1089,  0.0224],\n",
            "        ...,\n",
            "        [ 0.0731,  0.0158, -0.0272,  ...,  0.1536,  0.0036, -0.0639],\n",
            "        [-0.0720,  0.0294,  0.1752,  ...,  0.0933, -0.0616, -0.1404],\n",
            "        [ 0.0073,  0.1702, -0.0320,  ...,  0.1426,  0.0073, -0.0798]],\n",
            "       grad_fn=<CatBackward0>), batch_sizes=tensor([10, 10, 10, 10, 10,  9,  7,  7,  6,  6,  5,  5,  5,  5,  5,  4,  4,  3,\n",
            "         1,  1]), sorted_indices=None, unsorted_indices=None)\n",
            "torch.Size([123, 512])\n",
            "torch.Size([1, 10, 512])\n",
            "torch.Size([1, 10, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArOrgjHjZqAa",
        "outputId": "cb2ff2bb-0d6c-4551-e5b6-6f520134fb04"
      },
      "source": [
        "outputs, output_lens = pad_packed_sequence(packed_outputs)\n",
        "print(outputs.shape)\n",
        "print(output_lens)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([20, 10, 512])\n",
            "tensor([20, 18, 18, 17, 15, 10,  8,  6,  6,  5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meuNwIIn-H-g"
      },
      "source": [
        "### **GRU 사용**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMUysrtLihqt"
      },
      "source": [
        "GRU는 cell state가 없어 RNN과 동일하게 사용 가능합니다.   \n",
        "GRU를 이용하여 LM task를 수행해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHw8PSf--lVg"
      },
      "source": [
        "num_layers = 1\n",
        "num_dirs = 1\n",
        "dropout=0.1\n",
        "\n",
        "# ---------------------fill in ------------------------\n",
        "gru = nn.GRU(\n",
        "    input_size=embedding_size,\n",
        "    hidden_size=hidden_size,\n",
        "    num_layers=num_layers,\n",
        "    bidirectional=True if num_dirs > 1 else False\n",
        ")\n",
        "# ---------------------fill in ------------------------"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbMy2CkWzobD"
      },
      "source": [
        "output_layer = nn.Linear(hidden_size, vocab_size)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YavlcFZywCBK"
      },
      "source": [
        "input_id = batch.transpose(0, 1)[0, :]  # (B)\n",
        "hidden = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))  # (1, B, d_h)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_id) # \"i study very harder...\"\n",
        "print(input_id.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AccS0xaOYLOv",
        "outputId": "83390eba-985a-413d-93dd-918ead746eac"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([84, 44, 50,  8, 14, 56,  7,  7, 44,  5])\n",
            "torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQxISUUDYb42",
        "outputId": "92030ddd-c14f-4e3e-81d8-a24b6b7ceded"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1tFGyvo-uHb"
      },
      "source": [
        "Teacher forcing 없이 이전에 얻은 결과를 다음 input으로 이용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6HRC3TAxtGa",
        "outputId": "2c17772b-d7ff-43ea-ccb6-ae9d060eb77b"
      },
      "source": [
        "for t in range(max_len):\n",
        "# ---------------------fill in ------------------------\n",
        "  input_emb = embedding(input_id).unsqueeze(0)\n",
        "  \n",
        "  \"\"\"\n",
        "  input_emb = [1, 10, 256] \n",
        "  hidden    = [1, 10, 512]\n",
        "  \"\"\"\n",
        "  output, hidden = gru(input_emb, hidden) # output: (1, B, 2d_h), hidden: (1, B, d_h)\n",
        "  '''\n",
        "  output = [1, 10, 512] \n",
        "  hidden    = [1, 10, 512]\n",
        "  '''\n",
        "\n",
        "  # V: vocab size\n",
        "  output = output_layer(output) # (1, B, V)\n",
        "\n",
        "  \"\"\"\n",
        "  vocab = 3\n",
        "  B=1\n",
        "  output = [[1.3, 2.9, -0.7, 0.3]]\n",
        "  probs(2.9), top_id(token index) =torch.max(output, dim=-1)\n",
        "  \"\"\"\n",
        "  \n",
        "  probs, top_id = torch.max(output, dim=-1) # probs: (1, B), top_id: (1, B)\n",
        "# ---------------------fill in ------------------------\n",
        "\n",
        "  print(\"*\" * 50)\n",
        "  print(f\"Time step: {t}\")\n",
        "  print(output.shape)\n",
        "  print(probs.shape)\n",
        "  print(top_id.shape)\n",
        "\n",
        "  input_id = top_id.squeeze(0)  # (B)\n",
        "  print(input_id)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 512]) torch.Size([1, 10, 512])\n",
            "**************************************************\n",
            "Time step: 0\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "tensor([84, 69, 57, 53, 14, 51, 51, 51, 69,  4])\n",
            "torch.Size([1, 10, 512]) torch.Size([1, 10, 512])\n",
            "**************************************************\n",
            "Time step: 1\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "tensor([79, 45, 57,  2, 14, 44, 51, 51, 45, 57])\n",
            "torch.Size([1, 10, 512]) torch.Size([1, 10, 512])\n",
            "**************************************************\n",
            "Time step: 2\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "tensor([26, 18, 78, 58, 14, 19, 44, 44, 18,  4])\n",
            "torch.Size([1, 10, 512]) torch.Size([1, 10, 512])\n",
            "**************************************************\n",
            "Time step: 3\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "tensor([84,  5, 62, 60, 14, 31, 19, 19,  5, 57])\n",
            "torch.Size([1, 10, 512]) torch.Size([1, 10, 512])\n",
            "**************************************************\n",
            "Time step: 4\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "tensor([79, 97, 21, 64, 14, 31, 31, 31, 97, 57])\n",
            "torch.Size([1, 10, 512]) torch.Size([1, 10, 512])\n",
            "**************************************************\n",
            "Time step: 5\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "tensor([26, 83, 38, 51, 14,  7, 31, 31, 83, 78])\n",
            "torch.Size([1, 10, 512]) torch.Size([1, 10, 512])\n",
            "**************************************************\n",
            "Time step: 6\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "tensor([84, 50, 83, 51, 14,  4,  7,  7, 50, 62])\n",
            "torch.Size([1, 10, 512]) torch.Size([1, 10, 512])\n",
            "**************************************************\n",
            "Time step: 7\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "tensor([79, 27, 39, 44, 14, 57,  4,  4, 27, 21])\n",
            "torch.Size([1, 10, 512]) torch.Size([1, 10, 512])\n",
            "**************************************************\n",
            "Time step: 8\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "tensor([26, 83, 76, 19, 14,  4, 57, 57, 83, 38])\n",
            "torch.Size([1, 10, 512]) torch.Size([1, 10, 512])\n",
            "**************************************************\n",
            "Time step: 9\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "tensor([84,  8, 67, 31, 14, 57,  4,  4,  8, 83])\n",
            "torch.Size([1, 10, 512]) torch.Size([1, 10, 512])\n",
            "**************************************************\n",
            "Time step: 10\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "tensor([79, 68, 44, 31, 14, 57, 57, 57, 68, 39])\n",
            "torch.Size([1, 10, 512]) torch.Size([1, 10, 512])\n",
            "**************************************************\n",
            "Time step: 11\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "tensor([26, 22, 19,  7, 14, 78, 57, 57, 22, 76])\n",
            "torch.Size([1, 10, 512]) torch.Size([1, 10, 512])\n",
            "**************************************************\n",
            "Time step: 12\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "tensor([84, 53, 24,  4, 14, 62, 78, 78, 53, 67])\n",
            "torch.Size([1, 10, 512]) torch.Size([1, 10, 512])\n",
            "**************************************************\n",
            "Time step: 13\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "tensor([79,  2, 92, 57, 14, 21, 62, 62,  2, 44])\n",
            "torch.Size([1, 10, 512]) torch.Size([1, 10, 512])\n",
            "**************************************************\n",
            "Time step: 14\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "tensor([26, 58, 95,  4, 14, 38, 21, 21, 58, 19])\n",
            "torch.Size([1, 10, 512]) torch.Size([1, 10, 512])\n",
            "**************************************************\n",
            "Time step: 15\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "tensor([84, 60, 76, 57, 14, 83, 38, 38, 60, 24])\n",
            "torch.Size([1, 10, 512]) torch.Size([1, 10, 512])\n",
            "**************************************************\n",
            "Time step: 16\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "tensor([79, 64, 39, 57, 14, 39, 83, 83, 64, 92])\n",
            "torch.Size([1, 10, 512]) torch.Size([1, 10, 512])\n",
            "**************************************************\n",
            "Time step: 17\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "tensor([26, 51, 76, 78, 14, 76, 39, 39, 51, 95])\n",
            "torch.Size([1, 10, 512]) torch.Size([1, 10, 512])\n",
            "**************************************************\n",
            "Time step: 18\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "tensor([84, 51, 64, 62, 14, 67, 76, 76, 51, 76])\n",
            "torch.Size([1, 10, 512]) torch.Size([1, 10, 512])\n",
            "**************************************************\n",
            "Time step: 19\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "tensor([79, 44,  1, 21, 14, 44, 67, 67, 44, 39])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WY3vh9Cm4KaH"
      },
      "source": [
        "`max_len`만큼의 for 문을 돌면서 모든 결과물의 모양을 확인했지만 만약 종료 조건(예를 들어 문장의 끝을 나타내는 end token 등)이 되면 중간에 생성을 그만둘 수도 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l07L_QncemE7"
      },
      "source": [
        "### **양방향 및 여러 layer 사용**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lasjjz-teohw"
      },
      "source": [
        "이번엔 양방향 + 2개 이상의 layer를 쓸 때 얻을 수 있는 결과에 대해 알아봅니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEy00WX3ghsb"
      },
      "source": [
        "num_layers = 2\n",
        "num_dirs = 2\n",
        "dropout=0.1\n",
        "\n",
        "# ---------------------fill in ------------------------\n",
        "gru = nn.GRU(\n",
        "    input_size=embedding_size,\n",
        "    hidden_size=hidden_size,\n",
        "    num_layers=num_layers,\n",
        "    bidirectional=True if num_dirs > 1 else False, \n",
        "    dropout=dropout\n",
        "\n",
        ")\n",
        "# ---------------------fill in ------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QX4LVL_Ag4kK"
      },
      "source": [
        "Bidirectional이 되었고 layer의 개수가 $2$로 늘었기 때문에 hidden state의 shape도 `(4, B, d_h)`가 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8aBk8yrfOHU",
        "outputId": "e01648c7-8836-4e5c-a2e6-f6b455d73473"
      },
      "source": [
        "# d_w: word embedding size, num_layers: layer의 개수, num_dirs: 방향의 개수\n",
        "batch_emb = embedding(batch)  # (B, L, d_w)\n",
        "h_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))  # (num_layers * num_dirs, B, d_h) = (4, B, d_h)\n",
        "\n",
        "packed_batch = pack_padded_sequence(batch_emb.transpose(0, 1), batch_lens)\n",
        "\n",
        "packed_outputs, h_n = gru(packed_batch, h_0)\n",
        "print(packed_outputs)\n",
        "print(packed_outputs[0].shape)\n",
        "print(h_n.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PackedSequence(data=tensor([[-0.1285, -0.2120, -0.1383,  ..., -0.0258,  0.1617, -0.0013],\n",
            "        [-0.0206,  0.0359,  0.0159,  ...,  0.2427,  0.1672,  0.0439],\n",
            "        [ 0.1641, -0.0597, -0.0626,  ...,  0.1544,  0.0090, -0.0756],\n",
            "        ...,\n",
            "        [-0.1863, -0.2344, -0.0661,  ...,  0.0136, -0.0320, -0.0242],\n",
            "        [ 0.0655,  0.2947, -0.1015,  ...,  0.1307,  0.0216,  0.0740],\n",
            "        [-0.0233,  0.3113, -0.1019,  ...,  0.0490, -0.0530,  0.0408]],\n",
            "       grad_fn=<CatBackward0>), batch_sizes=tensor([10, 10, 10, 10, 10,  9,  7,  7,  6,  6,  5,  5,  5,  5,  5,  4,  4,  3,\n",
            "         1,  1]), sorted_indices=None, unsorted_indices=None)\n",
            "torch.Size([123, 1024])\n",
            "torch.Size([4, 10, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQdVtMcehndm",
        "outputId": "94e54ce1-99c0-4c38-c8dc-4179fe6ff64a"
      },
      "source": [
        "outputs, output_lens = pad_packed_sequence(packed_outputs)\n",
        "\n",
        "print(outputs.shape)  # (L, B, num_dirs*d_h)\n",
        "print(output_lens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([20, 10, 1024])\n",
            "tensor([20, 18, 18, 17, 15, 10,  8,  6,  6,  5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byuggMjekUxS"
      },
      "source": [
        "각각의 결과물의 shape는 다음과 같습니다.\n",
        "\n",
        "`outputs`: `(max_len, batch_size, num_dir * hidden_size)`  \n",
        "`h_n`: `(num_layers*num_dirs, batch_size, hidden_size)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaXhvyHjmFR3",
        "outputId": "afbb93db-bac8-4de2-a47e-cd69ce4f2b14"
      },
      "source": [
        "batch_size = h_n.shape[1]\n",
        "print(h_n.view(num_layers, num_dirs, batch_size, hidden_size))\n",
        "print(h_n.view(num_layers, num_dirs, batch_size, hidden_size).shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[-0.2689,  0.0110, -0.1929,  ..., -0.0579,  0.0036,  0.0836],\n",
            "          [ 0.2984,  0.3071,  0.0379,  ...,  0.1410, -0.1182, -0.0310],\n",
            "          [ 0.1746,  0.1269,  0.0330,  ...,  0.1730,  0.1507, -0.0148],\n",
            "          ...,\n",
            "          [-0.2431, -0.1091, -0.1690,  ..., -0.4644,  0.0827, -0.0422],\n",
            "          [ 0.2090,  0.2645, -0.0849,  ..., -0.1089,  0.4029,  0.3485],\n",
            "          [ 0.2493,  0.1232,  0.3311,  ..., -0.6174, -0.1057, -0.0204]],\n",
            "\n",
            "         [[ 0.0395,  0.1376, -0.0006,  ...,  0.0817,  0.1123, -0.1046],\n",
            "          [-0.2117,  0.2740,  0.1468,  ..., -0.2215,  0.0311, -0.1055],\n",
            "          [ 0.0176, -0.1075, -0.3544,  ..., -0.0254,  0.1983,  0.1208],\n",
            "          ...,\n",
            "          [ 0.1363,  0.1988,  0.0142,  ...,  0.2764,  0.0210,  0.0185],\n",
            "          [ 0.2546,  0.2235,  0.1026,  ...,  0.1578, -0.2621,  0.2308],\n",
            "          [ 0.2374,  0.5016,  0.2796,  ..., -0.0438, -0.2114, -0.2502]]],\n",
            "\n",
            "\n",
            "        [[[-0.0233,  0.3113, -0.1019,  ..., -0.2586,  0.1278, -0.0752],\n",
            "          [-0.1699,  0.1048, -0.0260,  ...,  0.0481,  0.2687, -0.0126],\n",
            "          [-0.1863, -0.2344, -0.0661,  ...,  0.0972,  0.1082,  0.0823],\n",
            "          ...,\n",
            "          [-0.1277,  0.0651,  0.0237,  ...,  0.2663,  0.1634,  0.1929],\n",
            "          [-0.0963,  0.2751,  0.0812,  ..., -0.0175,  0.0755, -0.1002],\n",
            "          [-0.1221,  0.0829,  0.2060,  ...,  0.2674,  0.2998,  0.0501]],\n",
            "\n",
            "         [[ 0.0563, -0.0444,  0.0850,  ..., -0.0258,  0.1617, -0.0013],\n",
            "          [ 0.1305, -0.0693,  0.1687,  ...,  0.2427,  0.1672,  0.0439],\n",
            "          [-0.3034,  0.0288,  0.1064,  ...,  0.1544,  0.0090, -0.0756],\n",
            "          ...,\n",
            "          [ 0.1113, -0.1106, -0.0468,  ...,  0.0405,  0.0079,  0.2302],\n",
            "          [-0.1675,  0.0201,  0.1374,  ...,  0.0278, -0.0081,  0.0572],\n",
            "          [-0.0533,  0.0655, -0.1090,  ...,  0.2327, -0.0150, -0.0941]]]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "torch.Size([2, 2, 10, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qZk_Mhp6Hx_7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}